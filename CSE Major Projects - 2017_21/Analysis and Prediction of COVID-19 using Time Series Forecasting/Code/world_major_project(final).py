# -*- coding: utf-8 -*-
"""World-Major-Project(Final).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZY1Gemqjk6AHt7JMHlLxsFvv9GHotEWS

# **Importing all the required libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
! pip install wget

# Data Processing
import numpy as np
import pandas as pd
import wget
from datetime import datetime, timedelta

from sklearn.preprocessing import PolynomialFeatures 
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from statsmodels.tsa.api import Holt,SimpleExpSmoothing,ExponentialSmoothing
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import r2_score
import statsmodels.api as sm
from sklearn.metrics import mean_absolute_error as mae

# visualization
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objs as go
import plotly.figure_factory as ff
import folium
# %matplotlib inline

# hide warnings
import warnings
warnings.filterwarnings('ignore')

# html embedding
from IPython.display import Javascript
from IPython.core.display import display, HTML

# set formatting
pd.set_option('display.max_columns', 100)
pd.set_option('display.max_rows', 100)

print("Setup Complete")

yesterday = datetime.today() - timedelta(days=2)
yesterday = yesterday.strftime('%m-%d-%Y')

yesterday

# url of the raw csv dataset
urls = [
    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',
    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv',
    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv',
    f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{yesterday}.csv'
]
[wget.download(url) for url in urls]

confirmed_df = pd.read_csv('time_series_covid19_confirmed_global.csv')
death_df = pd.read_csv('time_series_covid19_deaths_global.csv')
recovered_df = pd.read_csv('time_series_covid19_recovered_global.csv')
df = pd.read_csv(f'{yesterday}.csv')
#df.head()
df.tail()

confirmed_df.head()

"""# **Data preprocessing**

"""

#Extracting datewise data
dates = confirmed_df.columns[4:] #Dates

confirmed_df_long = confirmed_df.melt(
    id_vars=['Province/State', 'Country/Region',], 
    value_vars=dates, 
    var_name='Date', 
    value_name='Confirmed'
)

death_df_long = death_df.melt(
    id_vars=['Province/State', 'Country/Region',], 
    value_vars=dates, 
    var_name='Date', 
    value_name='Deaths'
)

recovered_df_long = recovered_df.melt(
    id_vars=['Province/State', 'Country/Region',], 
    value_vars=dates, 
    var_name='Date', 
    value_name='Recovered'
)

recovered_df_long

confirmed_df_long

# Merging confirmed_df_long and death_df_long
full_table = confirmed_df_long.merge(
  right=death_df_long, 
  how='left'
)

# Merging full_table and recovered_df_long
full_table = full_table.merge(
  right=recovered_df_long, 
  how='left'
)
full_table.head()

"""##**Data Cleaning**

There are 2 tasks we would like to do:

Replacing missing value NaN\
Coronavirus cases reported from 3 cruise ships should be treated differently
"""

full_table['Date'] = pd.to_datetime(full_table['Date'])
full_table.isna().sum()

"""Their are NaN values in Provision/State since many countries only report country wise but there are 3648 NaNs in Recovered; replacing them with 0.


"""

full_table['Recovered'] = full_table['Recovered'].fillna(0).astype(int)

"""Apart from missing values, there are COVID-19 cases reported from 3 cruise ships:

Grand Princess
Diamond Princess
MS Zaandam
These data need to be extracted and treated differently due to Province/State and Country/Region mismatch over time.
"""

ship_rows = full_table['Province/State'].str.contains('Grand Princess') | full_table['Province/State'].str.contains('Diamond Princess') | full_table['Country/Region'].str.contains('Diamond Princess') | full_table['Country/Region'].str.contains('MS Zaandam')

ship_df = full_table[ship_rows]
ship_df.head()

full_table = full_table[~(ship_rows)]

"""##**Data Aggregation**

Adding additional column - active cases :
active = confirmed — deaths — recovered
"""

full_table['Active'] = full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']
full_table.head()

"""Aggregating data into Country/Region wise and grouping them by Date and Country/Region


"""

full_grouped = full_table.groupby(['Date', 'Country/Region'])['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()
full_grouped

"""Adding day wise New Cases, New Deaths, New Recovered


"""

# new cases 
temp = full_grouped.groupby(['Country/Region', 'Date', ])['Confirmed', 'Deaths', 'Recovered']
temp = temp.sum().diff().reset_index()

mask = temp['Country/Region'] != temp['Country/Region'].shift(1)

temp.loc[mask, 'Confirmed'] = np.nan
temp.loc[mask, 'Deaths'] = np.nan
temp.loc[mask, 'Recovered'] = np.nan

# renaming columns
temp.columns = ['Country/Region', 'Date', 'New cases', 'New deaths', 'New recovered']

# merging new values
full_grouped = pd.merge(full_grouped, temp, on=['Country/Region', 'Date'])

# filling na with 0
full_grouped = full_grouped.fillna(0)

# fixing data types
cols = ['New cases', 'New deaths', 'New recovered']
full_grouped[cols] = full_grouped[cols].astype('int')

# 
full_grouped['New cases'] = full_grouped['New cases'].apply(lambda x: 0 if x<0 else x)
full_grouped.tail()

"""#**Data Analysis and Visualization**

##**World and country-wise data**
"""

temp = full_grouped.groupby('Date')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()
temp = temp[temp['Date']==max(temp['Date'])].reset_index(drop=True)
world_cases = temp.to_numpy()
temp.style.background_gradient(cmap='Pastel1')
#World-wide cases

temp = full_grouped.groupby(['Country/Region'])['Confirmed', 'Deaths', 'Recovered', 'Active', 'New cases', 'New deaths', 'New recovered'].max() #Sorting by taking confirmed cases
temp.sort_values('Confirmed', ascending=False).style.bar(subset=['Confirmed', 'Deaths', 'Recovered', 'Active', 'New cases', 'New deaths', 'New recovered'],
                                                         align = 'left', color='#d65f5f')

"""##**Number of confirmed, active, deaths, recoveries, mortality rate (CFR), and recovery rate world-wide**

###**Number of confirmed, active , deaths, recoveries**
"""

temp = full_grouped.groupby('Date')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()
temp = temp.melt(id_vars="Date", value_vars=['Confirmed', 'Deaths', 'Recovered', 'Active'],
                 var_name='Case', value_name='Count')
print(temp)
fig = px.line(temp, x="Date", y="Count", color='Case',
             title='Cases over time')
fig

fig = px.bar(temp, x="Date", y="Count", color='Case',
             title='Cases over time')
fig

#temp = temp[~(temp.Case == 'Confirmed')]
fig = px.pie(temp, values='Count', names='Case', title= 'Cases')
fig.update_traces(textinfo='percent+label')
fig.show()

"""###**Recovery and Mortality Rate**"""

temp = full_grouped
# adding two more columns
temp['Mortality Rate'] = round(temp['Deaths']/temp['Confirmed'], 3)
temp['Recovery Rate'] = round(temp['Recovered']/temp['Confirmed'], 3)

temp.groupby(['Country/Region'])['Recovery Rate','Mortality Rate'].max().sort_values('Recovery Rate', ascending=False).style.background_gradient(cmap='Reds')
#Sort by recovery rate

temp = full_grouped.groupby('Date').sum().reset_index()

temp['Mortality Rate'] = round(temp['Deaths']/temp['Confirmed'], 3)
temp['Recovery Rate'] = round(temp['Recovered']/temp['Confirmed'], 3)

temp = temp.melt(id_vars='Date', value_vars=['Mortality Rate', 'Recovery Rate'],var_name='Ratio', value_name='Value')
print(temp)
fig = px.line(temp, x="Date", y="Value", color='Ratio',title='Recovery and Mortality Rate Over The Time')
fig

fig = px.bar(temp, x="Date", y="Value", color='Ratio',title='Recovery and Mortality Rate Over The Time')
fig

"""###**World daily increases in new cases, deaths and recoveries**"""

temp = full_grouped.groupby('Date')['New cases', 'New deaths', 'New recovered'].sum().reset_index()
temp = temp.melt(id_vars="Date", value_vars=['New cases', 'New deaths', 'New recovered'],var_name='Case', value_name='Count')
#temp.head()
print(temp)
fig = px.line(temp, x="Date", y="Count", color='Case',title='Daily Cases')
fig

fig = px.bar(temp, x="Date", y="Count", color='Case',
             title='Daily Cases')
fig

fig = px.pie(temp, values='Count', names='Case', title='Daily Cases')
fig.update_traces(textinfo='percent+value+label')
fig.show()

"""#**Country Specific Graphs**

"""

country_grouped = df.groupby('Country_Region')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()

country_grouped['Active'] = country_grouped['Active'].astype(int)

"""##**Confirmed Cases**"""

country_grouped = country_grouped.sort_values('Confirmed', ascending=False)

others_series = pd.Series(np.sum(country_grouped[10:]))
country_grouped_others = country_grouped[:10] #First ten countries
country_grouped_others = country_grouped_others.append(others_series, ignore_index=True)
country_grouped_others.iloc[10,0] = 'Rest of the World'
#print(country_grouped_others)

# Confirmed Cases
fig = px.choropleth(country_grouped, locations="Country_Region", 
                    locationmode='country names', color="Confirmed", 
                    hover_name="Country_Region", range_color=[1,700000], 
                    color_continuous_scale="aggrnyl", 
                    title='Countries with Confirmed Cases')
fig

fig = px.pie(country_grouped_others, values='Confirmed', names='Country_Region', title='Confirmed Cases')
fig.update_traces(textinfo='percent+label')
fig.show()

fig = px.bar(country_grouped.head(20).sort_values('Confirmed', ascending=True), 
             x="Confirmed", y="Country_Region",title='Top 20 Countries Confirmed Cases', 
             text='Confirmed', orientation='h', 
             width=700, height=700)
fig.update_traces(opacity=0.6)
fig

"""##**Deaths**"""

# Deaths
fig = px.choropleth(country_grouped[country_grouped['Deaths']>0], 
                    locations="Country_Region", locationmode='country names',
                    color="Deaths", hover_name="Country_Region", 
                    range_color=[1,50000], color_continuous_scale="agsunset",
                    title='Countries with Deaths Reported')
fig

fig = px.pie(country_grouped_others.sort_values('Deaths', ascending=False), values='Deaths', names='Country_Region', title='Total Deaths')
fig.update_traces(textinfo='percent+label')
fig.show()

fig = px.bar(country_grouped.sort_values('Deaths', ascending=False).head(20).sort_values('Deaths', ascending=True), 
             x="Deaths", y="Country_Region", title='Top 20 Countries Deaths', text='Deaths', orientation='h', 
             width=700, height=700)
fig.update_traces(opacity=0.6)
fig

"""##**Recovered Cases**"""

# Recoveries
fig = px.choropleth(country_grouped[country_grouped['Recovered']>0], 
                    locations="Country_Region", locationmode='country names',
                    color="Recovered", hover_name="Country_Region", 
                    range_color=[1,50000], color_continuous_scale="agsunset",
                    title='Countries Recovered Cases')
fig

fig = px.pie(country_grouped_others.sort_values('Recovered', ascending=False), values='Recovered', names='Country_Region', title='Total Recovered')
fig.update_traces(textinfo='percent+label')
fig.show()

fig = px.bar(country_grouped.sort_values('Recovered', ascending=False).head(20).sort_values('Recovered', ascending=True), 
             x="Recovered", y="Country_Region", title='Top 20 Countries Recovered Cases', text='Recovered', orientation='h', 
             width=700, height=700)
fig.update_traces(opacity=0.6)
fig

"""##**Active cases**"""

# Active
fig = px.choropleth(country_grouped[country_grouped['Active']>0], 
                    locations="Country_Region", locationmode='country names',
                    color="Active", hover_name="Country_Region", 
                    range_color=[1,50000], color_continuous_scale="agsunset",
                    title='Countries Active Cases')
fig

fig = px.pie(country_grouped_others.sort_values('Active', ascending=False), values='Active', names='Country_Region', title='Total Active Cases')
fig.update_traces(textinfo='percent+label')
fig.show()

fig = px.bar(country_grouped.sort_values('Active', ascending=False).head(20).sort_values('Active', ascending=True), 
             x="Active", y="Country_Region", title='Top 20 Countries Active Cases', text='Active', orientation='h', 
             width=700, height=700)
fig.update_traces(opacity=0.6)
fig

"""#**Progression of Virus Over Time**

##**Confirmed cases**
"""

# https://app.flourish.studio/visualisation/1571387/edit
HTML('''<div class="flourish-embed flourish-bar-chart-race" data-src="visualisation/6253280"><script src="https://public.flourish.studio/resources/embed.js"></script></div>''')

"""##**Deaths**"""

HTML('''<div class="flourish-embed flourish-bar-chart-race" data-src="visualisation/6253291"><script src="https://public.flourish.studio/resources/embed.js"></script></div>''')

"""##**Recovered cases**"""

HTML(''' <div class="flourish-embed flourish-bar-chart-race" data-src="visualisation/6253324"><script src="https://public.flourish.studio/resources/embed.js"></script></div>''')

"""#**Country specific(India) confirmed, death, recovered cases graph**

"""

def cdr_graph(df, region):
    """
    Input:
        df of type :
            * Date: datetime64[ns]
            * Country/Region: object
            * Confirmed: int64
            * Deaths: int64
            * Recovered: int64
            * Active: int64
            * New cases: int64
            * New deaths: int64
            * New recovered: int64
            * Mortality Rate: float64
            * Recovery Rate: float64<br>
            dtype: object
        region of df: String
    return:
        line, area, bar Graphs of ['Confirmed', 'Deaths', 'Recovered', 'Active'] cases 

    """
    temp = df.groupby('Date')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()
    temp = temp.melt(id_vars="Date", value_vars=['Confirmed', 'Deaths', 'Recovered', 'Active'],
                 var_name='Case', value_name='Count')

    line = px.line(temp, x="Date", y="Count", color='Case',
             title=f'{region} Cases over time')
    area = px.area(temp, x="Date", y="Count", color='Case',
             title=f'{region} Cases over time')
    bar = px.bar(temp, x="Date", y="Count", color='Case',
             title=f'{region} Cases over time')
    temp = temp[~(temp.Case == 'Confirmed')]
    pie = px.pie(temp, values='Count', names='Case', title='Confirmed Cases')
    pie.update_traces(textinfo='percent+label')
    
    display(line)
    display(area)
    display(bar)
    display(pie)

def mr_graph(df, region):
    """
    Input:
        df of type :
            * Date: datetime64[ns]
            * Country/Region: object
            * Confirmed: int64
            * Deaths: int64
            * Recovered: int64
            * Active: int64
            * New cases: int64
            * New deaths: int64
            * New recovered: int64
            * Mortality Rate: float64
            * Recovery Rate: float64<br>
            dtype: object
        region of df: String
    return:
        line, bar Graphs of ['Mortality Rate', 'Recovery Rate'] cases 

    """
    temp = df.groupby('Date').sum().reset_index()

    temp['Mortality Rate'] = round(temp['Deaths']/temp['Confirmed'], 3)
    temp['Recovery Rate'] = round(temp['Recovered']/temp['Confirmed'], 3)

    temp = temp.melt(id_vars='Date', value_vars=['Mortality Rate', 'Recovery Rate'],var_name='Ratio', value_name='Value')

    line = px.line(temp, x="Date", y="Value", color='Ratio',title=f'Recovery and Mortality Rate of {region} Over The Time')
    bar = px.bar(temp, x="Date", y="Value", color='Ratio', title=f'Recovery and Mortality of {region} Rate Over The Time')
    display(line)
    display(bar)

def daily_graph(df, region):
    """
    Input:
        df of type :
            * Date: datetime64[ns]
            * Country/Region: object
            * Confirmed: int64
            * Deaths: int64
            * Recovered: int64
            * Active: int64
            * New cases: int64
            * New deaths: int64
            * New recovered: int64
            * Mortality Rate: float64
            * Recovery Rate: float64<br>
            dtype: object
        region of df: String
    return:
        line, area, bar Graphs of ['New cases', 'New deaths', 'New recovered'] cases 

    """
    temp = df.groupby('Date')['New cases', 'New deaths', 'New recovered'].sum().reset_index()
    temp = temp.melt(id_vars="Date", value_vars=['New cases', 'New deaths', 'New recovered'],
                     var_name='Case', value_name='Count')

    line = px.line(temp, x="Date", y="Count", color='Case', title=f'{region} Daily Cases')
   # area = px.area(temp, x="Date", y="Count", color='Case', title=f'{region} Daily Cases')
    bar = px.bar(temp, x="Date", y="Count", color='Case', title=f'{region} Daily Cases')
    pie = px.pie(temp, values='Count', names='Case', title='Confirmed Cases')
    pie.update_traces(textinfo='percent+label')
    
    display(line)
   # display(area)
    display(bar)
    display(pie)

""" India as example"""

india_data = full_grouped[full_grouped['Country/Region'] == 'India']

cdr_graph(india_data, 'India')

mr_graph(india_data, 'India')

daily_graph(india_data, 'India')

"""#**Predicting Confirmed Cases Worldwide**"""

# import Packages for Prediction
!pip install pmdarima
from pmdarima.arima import auto_arima
from sklearn.metrics import mean_squared_error
from datetime import timedelta
from fbprophet import Prophet

"""##**Data preprocessing**"""

# change Date column name
full_grouped = full_grouped.rename(columns = {'Date': 'ds'})

# Group data
df_group = full_grouped.groupby(by = 'ds')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum()

# change index to datetime
df_group.index = pd.to_datetime(df_group.index)

# Set frequncy of time series
df_group = df_group.asfreq(freq = '1D')

# Sort the values
df_group = df_group.sort_index(ascending = True)

# Fill NA values with zero
df_group = df_group.fillna(value = 0)

df_group = df_group.rename(columns = {'Date': 'ds'})

# Show the end of th data
display(df_group.tail())
display(df_group.head())

"""##**AR Model**"""

model_train = df_group.iloc[:int(df_group.shape[0]*0.95)]
valid = df_group.iloc[int(df_group.shape[0]*0.95):]
y_pred = valid.copy()
print(model_train,valid)

model_ar = auto_arima(model_train["Confirmed"],start_q=0,max_q=0,start_p = 0, max_p = 7,stepwise= False,method = 'cg',trace=True, error_action='ignore')
model_ar.fit(model_train["Confirmed"])

sample_len = len(valid)#to store the length of the sample
prediction_ar = model_ar.predict(sample_len)
#print(prediction_ar)
#print(y_pred)
print(sample_len)
y_pred["AR Model Prediction Confirmed" ]=prediction_ar
#print(y_pred)

#RMSE 
rmse_scores = [] #for storing rmse values of all the models
ar_rmse_score = (np.sqrt(mse(y_pred["Confirmed"],y_pred["AR Model Prediction Confirmed"])))/sample_len
rmse_scores.append(["AR RMSE Score:",ar_rmse_score])
print("Root Mean Square Error for AR Model: ",ar_rmse_score)
print(rmse_scores)

#MAE Score
mae_scores = []
ar_mae_score = mae(y_pred["Confirmed"],y_pred["AR Model Prediction Confirmed"])/sample_len
mae_scores.append(["AR MAE Score:", ar_mae_score])
print("AR- MAE Score:", ar_mae_score)
print(mae_scores)

#R2 Score
r2_scores = []
ar_r2_score = r2_score(y_pred["Confirmed"],y_pred["AR Model Prediction Confirmed"])
r2_scores.append(["AR R2 Score:", ar_r2_score])
print("AR- R2 Score:", ar_r2_score)
print(r2_scores)
#MSE Score
#mse_scores = []
#ar_mse = mse(y_pred["Confirmed"],y_pred["AR Model Prediction Confirmed"])
#mse_scores.append(["AR MSE Score:", ar_mse])
#print("AR- MSE Score:", ar_mse)
#print(mse_scores)

fig=go.Figure()
fig.add_trace(go.Scatter(x=model_train.index, y=model_train["Confirmed"],
                    mode='lines+markers',name="Train Data for Confirmed Cases"))
fig.add_trace(go.Scatter(x=valid.index, y=valid["Confirmed"],
                    mode='lines+markers',name="Validation Data for Confirmed Cases",))
fig.add_trace(go.Scatter(x=valid.index, y=y_pred["AR Model Prediction Confirmed"],
                    mode='lines',name="Prediction of Confirmed Cases",line=dict(color='black', dash='dot')))
fig.update_layout(title="Confirmed Cases AR Model Prediction",xaxis_title="Date",yaxis_title="Confirmed Cases")
fig.show()

AR_model_new_prediction=[]
new_date=[]
last_date = df_group.index[-1]
model = model_ar.predict(len(valid)+12)
#print(model)
# predicting next 20 days
for i in range(2,12):
    new_date.append(last_date+timedelta(days=i))
    print(model[len(valid)+i])
    AR_model_new_prediction.append(model[len(valid)+i])
#

pd.options.display.float_format = '{:.3f}'.format
model_predictions=pd.DataFrame(zip(new_date,AR_model_new_prediction),
                               columns=['Dates', 'AR_model_new_prediction'])
print(model_predictions)

"""##**MA Model**"""

model_train = df_group.iloc[:int(df_group.shape[0]*0.95)]
valid = df_group.iloc[int(df_group.shape[0]*0.95):]
y_pred = valid.copy()
model_ma= auto_arima(model_train["Confirmed"],trace=True, error_action='ignore',method='nm', start_p=0,max_p=0,start_q=0,max_q=5)
model_ma.fit(model_train["Confirmed"])

prediction_ma=model_ma.predict(len(valid))
y_pred["MA Model Prediction"]=prediction_ma

#RMSE 
ma_rmse_score = (np.sqrt(mse(valid["Confirmed"],prediction_ma)))/sample_len
rmse_scores.append(["MA RMSE Score:",ma_rmse_score])
print("Root Mean Square Error for MA Model: ",ma_rmse_score)
print(rmse_scores)

#MAE Score
ma_mae_score = mae(valid["Confirmed"],prediction_ma)/sample_len
mae_scores.append(["MA MAE Score:", ma_mae_score])
print("MA -MAE Score:", ma_mae_score)
print(mae_scores)

#R2 Score
ma_r2_score = r2_score(valid["Confirmed"],prediction_ma)
r2_scores.append(["MA R2 Score:", ma_r2_score])
print(" MA - R2 Score:", ma_r2_score)
print(r2_scores)

fig=go.Figure()
fig.add_trace(go.Scatter(x=model_train.index, y=model_train["Confirmed"],
                    mode='lines+markers',name="Train Data for Confirmed Cases"))
fig.add_trace(go.Scatter(x=valid.index, y=valid["Confirmed"],
                    mode='lines+markers',name="Validation Data for Confirmed Cases",))
fig.add_trace(go.Scatter(x=valid.index, y=y_pred["MA Model Prediction"],
                    mode='lines',name="Prediction for Confirmed Cases",line=dict(color='black', dash='dot')))
fig.update_layout(title="Confirmed Cases MA Model Prediction",
                 xaxis_title="Date",yaxis_title="Confirmed Cases")
fig.show()

MA_model_new_prediction=[]
for i in range(2, 12):
    MA_model_new_prediction.append(model_ma.predict(len(valid)+i)[-1])
model_predictions["MA Model Prediction"]=MA_model_new_prediction
print(model_predictions)

"""##**Holt's Linear Trend Model**"""

model_train=df_group.iloc[:int(df_group.shape[0]*0.95)]
valid=df_group.iloc[int(df_group.shape[0]*0.95):]
y_pred=valid.copy()

holt=Holt(np.asarray(model_train["Confirmed"])).fit(smoothing_level=0.2, smoothing_slope=0.2)
y_pred["Holt"]=holt.forecast(len(valid))

#RMSE 
hl_rmse_score = np.sqrt(mse(y_pred["Confirmed"],y_pred["Holt"]))/sample_len
rmse_scores.append(["Holt's Linear RMSE Score:",hl_rmse_score])
print("Root Mean Square Error for Holt's Linear Model: ",hl_rmse_score)
print(rmse_scores)

#MAE Score
hl_mae_score = mae(y_pred["Confirmed"],y_pred["Holt"])/sample_len
mae_scores.append(["Holt's Linear MAE Score", hl_mae_score])
print("olt's Linear MAE Score:", hl_mae_score)
print(mae_scores)

#R2 Score
hl_r2_score = r2_score(y_pred["Confirmed"],y_pred["Holt"])
r2_scores.append(["Holt's Linear R2 Score", hl_r2_score])
print("Holt's Linear R2 Score:", hl_r2_score)
print(r2_scores)

fig=go.Figure()
fig.add_trace(go.Scatter(x=model_train.index, y=model_train["Confirmed"],
                    mode='lines+markers',name="Train Data for Confirmed Cases"))
fig.add_trace(go.Scatter(x=valid.index, y=valid["Confirmed"],
                    mode='lines+markers',name="Validation Data for Confirmed Cases",))
fig.add_trace(go.Scatter(x=valid.index, y=y_pred["Holt"],
                    mode='lines',name="Prediction of Confirmed Cases",line=dict(color='black', dash='dot')))
fig.update_layout(title="Confirmed Cases Holt's Linear Model Prediction",
                 xaxis_title="Date",yaxis_title="Confirmed Cases",legend=dict(x=0,y=1,traceorder="normal"))
fig.show()

holt_new_prediction=[]
for i in range(2,12):
    holt_new_prediction.append(holt.forecast((len(valid)+i))[-1])

model_predictions["Holt's Linear Model Prediction"]=holt_new_prediction
model_predictions.head()

"""##**Holt's Winter Model**"""

model_train=df_group.iloc[:int(df_group.shape[0]*0.95)]
valid=df_group.iloc[int(df_group.shape[0]*0.95):]
y_pred=valid.copy()

es=ExponentialSmoothing(np.asarray(model_train['Confirmed']),seasonal_periods=11, trend='mul', seasonal='mul').fit()
y_pred["Holt's Winter Model"]=es.forecast(len(valid))

#RMSE 
hw_rmse_score = np.sqrt(mse(y_pred["Confirmed"],y_pred["Holt's Winter Model"]))/sample_len
rmse_scores.append(["Holt's Winter RMSE Score:",hw_rmse_score])
print("Root Mean Square Error for Holt's Winter Model: ",hw_rmse_score)
print(rmse_scores)

#MAE Score
hw_mae_score = mae(y_pred["Confirmed"],y_pred["Holt's Winter Model"])/sample_len
mae_scores.append(["Holt's Winter MAE Score", hw_mae_score])
print("Holt's Winter MAE Score:", hw_mae_score)
print(mae_scores)

#R2 Score
hw_r2_score = r2_score(y_pred["Confirmed"],y_pred["Holt's Winter Model"])
r2_scores.append(["Holt's Winter R2 Score", hw_r2_score])
print("Holt's Winter R2 Score:", hw_r2_score)
print(r2_scores)

fig=go.Figure()
fig.add_trace(go.Scatter(x=model_train.index, y=model_train["Confirmed"],
                    mode='lines+markers',name="Train Data for Confirmed Cases"))
fig.add_trace(go.Scatter(x=valid.index, y=valid["Confirmed"],
                    mode='lines+markers',name="Validation Data for Confirmed Cases",))
fig.add_trace(go.Scatter(x=valid.index, y=y_pred["Holt\'s Winter Model"],
                    mode='lines',name="Prediction of Confirmed Cases",line=dict(color='black', dash='dot')))
fig.update_layout(title="Confirmed Cases Holt's Winter Model Prediction",
                 xaxis_title="Date",yaxis_title="Confirmed Cases",legend=dict(x=0,y=1,traceorder="normal"))
fig.show()

holt_winter_new_prediction=[]
for i in range(2,12):
    holt_winter_new_prediction.append(es.forecast((len(valid)+i))[-1])
model_predictions["Holt's Winter Model Prediction"]=holt_winter_new_prediction
model_predictions.head()

"""##**ARIMA Model**"""

model_train = df_group.iloc[:int(df_group.shape[0]*0.95)]
valid = df_group.iloc[int(df_group.shape[0]*0.95):]
y_pred = valid.copy()
print(model_train)

model_arima= auto_arima(model_train["Confirmed"],method='cg',trace=True,stepwise=False,start_p=0,start_q=0,max_p=2,max_q=2)
model_arima.fit(model_train["Confirmed"])

prediction_arima=model_arima.predict(len(valid))
y_pred["ARIMA Model Prediction"]=prediction_arima

#RMSE 
arima_rmse_score = np.sqrt(mse(valid["Confirmed"],prediction_arima))/sample_len
rmse_scores.append(["ARIMA RMSE Score:",arima_rmse_score])
print("Root Mean Square Error for ARIMA Model: ",arima_rmse_score)
print(rmse_scores)

#MAE Score
arima_mae_score = mae(valid["Confirmed"],prediction_arima)/sample_len
mae_scores.append(["ARIMA MAE Score", arima_mae_score])
print("ARIMA MAE Score:", arima_mae_score)
print(mae_scores)

#R2 Score
arima_r2_score = r2_score(valid["Confirmed"],prediction_arima)
r2_scores.append(["ARIMA R2 Score", arima_r2_score])
print("ARIMA R2 Score:", arima_r2_score)
print(r2_scores)

fig=go.Figure()
fig.add_trace(go.Scatter(x=model_train.index, y=model_train["Confirmed"],
                    mode='lines+markers',name="Train Data for Confirmed Cases"))
fig.add_trace(go.Scatter(x=valid.index, y=valid["Confirmed"],
                    mode='lines+markers',name="Validation Data for Confirmed Cases",))
fig.add_trace(go.Scatter(x=valid.index, y=y_pred["ARIMA Model Prediction"],
                    mode='lines',name="Prediction for Confirmed Cases",line=dict(color='black', dash='dot')))
fig.update_layout(title="Confirmed Cases ARIMA Model Prediction",
                 xaxis_title="Date",yaxis_title="Confirmed Cases")
fig.show()

ARIMA_model_new_prediction=[]
for i in range(2,12):
    ARIMA_model_new_prediction.append(model_arima.predict(len(valid)+i)[-1])
model_predictions["ARIMA Model Prediction"]=ARIMA_model_new_prediction
model_predictions.head()

"""##**Facebook Prophet Model**"""

df_prophet = df_group[['Confirmed']]
df_prophet = df_prophet.reset_index()
df_prophet = df_prophet.rename(columns = {'ds': 'ds', 'Confirmed': 'y'})
df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])
m = Prophet(
    growth='linear', n_changepoints=30, changepoint_range=0.85)
m.fit(df_prophet)

future = m.make_future_dataframe(periods = 37)
forecast = m.predict(future)
fbprophet_score = np.sqrt(mean_squared_error(df_group["Confirmed"],forecast['yhat'].head(df_group.shape[0])))
#model_scores.append(["FB_Prophet Model Score:",fbprophet_score])
#print("Root Mean Squared Error for Prophet Model: ",fbprophet_score)
#print(model_scores)

#RMSE 
fbprophet_rmse_score = np.sqrt(mse(df_group["Confirmed"],forecast['yhat'].head(df_group.shape[0])))/sample_len
rmse_scores.append(["FB Prophet RMSE Score:",fbprophet_rmse_score])
print("Root Mean Square Error for FB Prophet Model: ",fbprophet_rmse_score)
print(rmse_scores)

#MAE Score
fbprophet_mae_score = mae(df_group["Confirmed"],forecast['yhat'].head(df_group.shape[0]))/sample_len
mae_scores.append(["FB Prophet MAE Score", fbprophet_mae_score])
print("FB Prophet MAE Score:", fbprophet_mae_score)
print(mae_scores)

#R2 Score
fbprophet_r2_score = r2_score(df_group["Confirmed"],forecast['yhat'].head(df_group.shape[0]))
r2_scores.append(["FB Prophet R2 Score", fbprophet_r2_score])
print("FB Prophet R2 Score:", fbprophet_r2_score)
print(r2_scores)

figure = m.plot(forecast, xlabel = 'Date', ylabel = 'Confirmed Cases')

figure2 = m.plot_components(forecast)

model_predictions["Prophet's Prediction"]=list(forecast["yhat"].tail(10))
model_predictions.head()

"""#**Accuracy Metrics**

##**RMSE Summary**
"""

#RMSE
rmse_np = np.array(rmse_scores)
print(rmse_np)

"""##**MAE Summary**"""

#MAE 
mae_np = np.array(mae_scores)
print(mae_np)

"""##**R2 Score Summary**"""

#R2 Score 
r2_score_np = np.array(r2_scores)
print(r2_score_np)

"""##**Summary of all the accuracy metrics**"""

#Summary
rmse_summary = pd.DataFrame(rmse_scores,columns=["Model Name","Root Mean Squared Error"]).sort_values(["Root Mean Squared Error"])
mae_summary = pd.DataFrame(mae_scores,columns=["Model Name","Mean Absolute Error"]).sort_values(["Mean Absolute Error"])
r2_score_summary = pd.DataFrame(r2_scores,columns=["Model Name","R2 Score"]).sort_values(["R2 Score"],ascending = False)
print(rmse_summary,"\n\n",mae_summary,"\n\n",r2_score_summary)

"""#**Prediction of Recoveries, Deaths**

##**Holt's Winter Model for Deaths**
"""

model_train=df_group.iloc[:int(df_group.shape[0]*0.95)]
valid=df_group.iloc[int(df_group.shape[0]*0.95):]
y_pred=valid.copy()

es=ExponentialSmoothing(np.asarray(model_train['Deaths']),seasonal_periods=11, trend='mul', seasonal='mul').fit()
y_pred["Holt's Winter Model"]=es.forecast(len(valid))

#RMSE 
hw_rmse_score = np.sqrt(mse(y_pred["Deaths"],y_pred["Holt's Winter Model"]))/sample_len
rmse_scores.append(["Holt's Winter RMSE Score:",hw_rmse_score])
print("Root Mean Square Error for Holt's Winter Model: ",hw_rmse_score)
print(rmse_scores)

#MAE Score
hw_mae_score = mae(y_pred["Deaths"],y_pred["Holt's Winter Model"])/sample_len
mae_scores.append(["Holt's Winter MAE Score", hw_mae_score])
print("Holt's Winter MAE Score:", hw_mae_score)
print(mae_scores)

#R2 Score
hw_r2_score = r2_score(y_pred["Deaths"],y_pred["Holt's Winter Model"])
r2_scores.append(["Holt's Winter R2 Score", hw_r2_score])
print("Holt's Winter R2 Score:", hw_r2_score)
print(r2_scores)

fig=go.Figure()
fig.add_trace(go.Scatter(x=model_train.index, y=model_train["Deaths"],
                    mode='lines+markers',name="Train Data for Death Cases"))
fig.add_trace(go.Scatter(x=valid.index, y=valid["Deaths"],
                    mode='lines+markers',name="Validation Data for Death Cases",))
fig.add_trace(go.Scatter(x=valid.index, y=y_pred["Holt\'s Winter Model"],
                    mode='lines',name="Prediction of Death Cases",line=dict(color='black', dash='dot')))
fig.update_layout(title="Death Cases Holt's Winter Model Prediction",
                 xaxis_title="Date",yaxis_title="Death Cases",legend=dict(x=0,y=1,traceorder="normal"))
fig.show()

holt_winter_model_death_prediction=[]
new_date=[]
last_date = df_group.index[-1]
# predicting next 20 days
for i in range(1,10):
    new_date.append(last_date+timedelta(days=i))
    holt_winter_model_death_prediction.append(es.forecast((len(valid)+i))[-1])
#print(np.array(holt_winter_model_death_prediction))

pd.options.display.float_format = '{:.3f}'.format
death_prediction=pd.DataFrame(zip(new_date,holt_winter_model_death_prediction),
                               columns=['Dates', 'holt_winter_model_death_prediction'])
print(death_prediction)

"""##**Holt's Winter for Recoveries**"""

model_train=df_group.iloc[:int(df_group.shape[0]*0.95)]
valid=df_group.iloc[int(df_group.shape[0]*0.95):]
y_pred=valid.copy()

es=ExponentialSmoothing(np.asarray(model_train['Recovered']),seasonal_periods=7, trend='mul', seasonal='mul').fit()
y_pred["Holt's Winter Model"]=es.forecast(len(valid))

#RMSE 
hw_rmse_score = np.sqrt(mse(y_pred["Recovered"],y_pred["Holt's Winter Model"]))/sample_len
rmse_scores.append(["Holt's Winter RMSE Score:",hw_rmse_score])
print("Root Mean Square Error for Holt's Winter Model: ",hw_rmse_score)
print(rmse_scores)

#MAE Score
hw_mae_score = mae(y_pred["Recovered"],y_pred["Holt's Winter Model"])/sample_len
mae_scores.append(["Holt's Winter MAE Score", hw_mae_score])
print("Holt's Winter MAE Score:", hw_mae_score)
print(mae_scores)

#R2 Score
hw_r2_score = r2_score(y_pred["Recovered"],y_pred["Holt's Winter Model"])
r2_scores.append(["Holt's Winter R2 Score", hw_r2_score])
print("Holt's Winter R2 Score:", hw_r2_score)
print(r2_scores)

fig=go.Figure()
fig.add_trace(go.Scatter(x=model_train.index, y=model_train["Recovered"],
                    mode='lines+markers',name="Train Data for Recovered Cases"))
fig.add_trace(go.Scatter(x=valid.index, y=valid["Recovered"],
                    mode='lines+markers',name="Validation Data for Recovered Cases",))
fig.add_trace(go.Scatter(x=valid.index, y=y_pred["Holt\'s Winter Model"],
                    mode='lines',name="Prediction of Recovered Cases",line=dict(color='black', dash='dot')))
fig.update_layout(title="Recovered Cases Holt's Winter Model Prediction",
                 xaxis_title="Date",yaxis_title="Recovered Cases",legend=dict(x=0,y=1,traceorder="normal"))
fig.show()

holt_winter_model_recovered_prediction=[]
new_date=[]
last_date = df_group.index[-1]
# predicting next 20 days
for i in range(1,10):
    new_date.append(last_date+timedelta(days=i))
    holt_winter_model_recovered_prediction.append(es.forecast((len(valid)+i))[-1])
#print(np.array(holt_winter_model_death_prediction))

pd.options.display.float_format = '{:.3f}'.format
recovered_prediction=pd.DataFrame(zip(new_date,holt_winter_model_recovered_prediction),
                               columns=['Dates', 'holt_winter_model_recovered_prediction'])
print(recovered_prediction)

